<!-- HTML header for doxygen 1.8.15-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Toolkit for Adaptive Stochastic Modeling and Non-Intrusive ApproximatioN: Tasmanian v8.1: TasOptimization::GradientDescentState Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="tasmanian.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
    <div class="doxygen">
            <a href="http://www.doxygen.org/index.html">
                Doxygen
                </a> 1.9.1
    </div>
   <div id="projectname">Toolkit for Adaptive Stochastic Modeling and Non-Intrusive ApproximatioN: Tasmanian v8.1
           <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.svg"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('classTasOptimization_1_1GradientDescentState.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#friends">Friends</a> &#124;
<a href="classTasOptimization_1_1GradientDescentState-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">TasOptimization::GradientDescentState Class Reference<div class="ingroups"><a class="el" href="group__TasmanianOptimization.html">Optimization</a> &raquo; <a class="el" href="group__OptimizationState.html">Optimization States</a></div></div>  </div>
</div><!--header-->
<div class="contents">

<p>Stores the information about a gradient descent run.  
 <a href="classTasOptimization_1_1GradientDescentState.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="tsgGradientDescent_8hpp_source.html">tsgGradientDescent.hpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a04076aba572ab88c4dff88ad126ad30c"><td class="memItemLeft" align="right" valign="top"><a id="a04076aba572ab88c4dff88ad126ad30c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTasOptimization_1_1GradientDescentState.html#a04076aba572ab88c4dff88ad126ad30c">GradientDescentState</a> ()=delete</td></tr>
<tr class="memdesc:a04076aba572ab88c4dff88ad126ad30c"><td class="mdescLeft">&#160;</td><td class="mdescRight">The default constructor is NOT allowed. <br /></td></tr>
<tr class="separator:a04076aba572ab88c4dff88ad126ad30c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a747e57adfda28103da3d673059b41e0a"><td class="memItemLeft" align="right" valign="top"><a id="a747e57adfda28103da3d673059b41e0a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTasOptimization_1_1GradientDescentState.html#a747e57adfda28103da3d673059b41e0a">GradientDescentState</a> (const std::vector&lt; double &gt; &amp;x0, const double initial_stepsize)</td></tr>
<tr class="memdesc:a747e57adfda28103da3d673059b41e0a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor for a gradient descent state with the initial candidate <b>x</b> and stepsize <b>lambda0</b>. <br /></td></tr>
<tr class="separator:a747e57adfda28103da3d673059b41e0a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a898506298395ff63a1b6d8b47f260c41"><td class="memItemLeft" align="right" valign="top"><a id="a898506298395ff63a1b6d8b47f260c41"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTasOptimization_1_1GradientDescentState.html#a898506298395ff63a1b6d8b47f260c41">GradientDescentState</a> (const <a class="el" href="classTasOptimization_1_1GradientDescentState.html">GradientDescentState</a> &amp;source)=default</td></tr>
<tr class="memdesc:a898506298395ff63a1b6d8b47f260c41"><td class="mdescLeft">&#160;</td><td class="mdescRight">Copy constructor. <br /></td></tr>
<tr class="separator:a898506298395ff63a1b6d8b47f260c41"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad3bd6ab7f5e97b083c49e3da962550e0"><td class="memItemLeft" align="right" valign="top"><a id="ad3bd6ab7f5e97b083c49e3da962550e0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTasOptimization_1_1GradientDescentState.html#ad3bd6ab7f5e97b083c49e3da962550e0">GradientDescentState</a> (<a class="el" href="classTasOptimization_1_1GradientDescentState.html">GradientDescentState</a> &amp;&amp;source)=default</td></tr>
<tr class="memdesc:ad3bd6ab7f5e97b083c49e3da962550e0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Move constructor. <br /></td></tr>
<tr class="separator:ad3bd6ab7f5e97b083c49e3da962550e0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a41811cac438e8a9f901a7854810bf2bd"><td class="memItemLeft" align="right" valign="top"><a id="a41811cac438e8a9f901a7854810bf2bd"></a>
<a class="el" href="classTasOptimization_1_1GradientDescentState.html">GradientDescentState</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTasOptimization_1_1GradientDescentState.html#a41811cac438e8a9f901a7854810bf2bd">operator=</a> (<a class="el" href="classTasOptimization_1_1GradientDescentState.html">GradientDescentState</a> &amp;&amp;source)=default</td></tr>
<tr class="memdesc:a41811cac438e8a9f901a7854810bf2bd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Move assignment. <br /></td></tr>
<tr class="separator:a41811cac438e8a9f901a7854810bf2bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a266841b08985c7f4700f26cda5f0130a"><td class="memItemLeft" align="right" valign="top"><a id="a266841b08985c7f4700f26cda5f0130a"></a>
<a class="el" href="classTasOptimization_1_1GradientDescentState.html">GradientDescentState</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTasOptimization_1_1GradientDescentState.html#a266841b08985c7f4700f26cda5f0130a">operator=</a> (<a class="el" href="classTasOptimization_1_1GradientDescentState.html">GradientDescentState</a> &amp;source)=default</td></tr>
<tr class="memdesc:a266841b08985c7f4700f26cda5f0130a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Copy assignment. <br /></td></tr>
<tr class="separator:a266841b08985c7f4700f26cda5f0130a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add65a3813a0b3f7edfc04af6800d64d3"><td class="memItemLeft" align="right" valign="top"><a id="add65a3813a0b3f7edfc04af6800d64d3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTasOptimization_1_1GradientDescentState.html#add65a3813a0b3f7edfc04af6800d64d3">operator std::vector&lt; double &gt; &amp;</a> ()</td></tr>
<tr class="memdesc:add65a3813a0b3f7edfc04af6800d64d3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implicit conversion to the current candidate <b>x</b> by reference. <br /></td></tr>
<tr class="separator:add65a3813a0b3f7edfc04af6800d64d3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86abeb7aeea4d77b18a9a89481246423"><td class="memItemLeft" align="right" valign="top"><a id="a86abeb7aeea4d77b18a9a89481246423"></a>
size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTasOptimization_1_1GradientDescentState.html#a86abeb7aeea4d77b18a9a89481246423">getNumDimensions</a> () const</td></tr>
<tr class="memdesc:a86abeb7aeea4d77b18a9a89481246423"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return the number of dimensions. <br /></td></tr>
<tr class="separator:a86abeb7aeea4d77b18a9a89481246423"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a83229d3db80c45620b7c093ee1beedf8"><td class="memItemLeft" align="right" valign="top"><a id="a83229d3db80c45620b7c093ee1beedf8"></a>
double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTasOptimization_1_1GradientDescentState.html#a83229d3db80c45620b7c093ee1beedf8">getAdaptiveStepsize</a> () const</td></tr>
<tr class="memdesc:a83229d3db80c45620b7c093ee1beedf8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return the stepsize. <br /></td></tr>
<tr class="separator:a83229d3db80c45620b7c093ee1beedf8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a850e13087a8f62b401221a25c1214b12"><td class="memItemLeft" align="right" valign="top"><a id="a850e13087a8f62b401221a25c1214b12"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTasOptimization_1_1GradientDescentState.html#a850e13087a8f62b401221a25c1214b12">getX</a> (double x_out[]) const</td></tr>
<tr class="memdesc:a850e13087a8f62b401221a25c1214b12"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return the current candidate point. <br /></td></tr>
<tr class="separator:a850e13087a8f62b401221a25c1214b12"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0d2719af32a6ebf30158d96df373afdf"><td class="memItemLeft" align="right" valign="top"><a id="a0d2719af32a6ebf30158d96df373afdf"></a>
std::vector&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTasOptimization_1_1GradientDescentState.html#a0d2719af32a6ebf30158d96df373afdf">getX</a> () const</td></tr>
<tr class="memdesc:a0d2719af32a6ebf30158d96df373afdf"><td class="mdescLeft">&#160;</td><td class="mdescRight">Overload for when the output is a vector. <br /></td></tr>
<tr class="separator:a0d2719af32a6ebf30158d96df373afdf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac167993a5d156f544997b98ccddba2ce"><td class="memItemLeft" align="right" valign="top"><a id="ac167993a5d156f544997b98ccddba2ce"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTasOptimization_1_1GradientDescentState.html#ac167993a5d156f544997b98ccddba2ce">setAdaptiveStepsize</a> (const double new_stepsize)</td></tr>
<tr class="memdesc:ac167993a5d156f544997b98ccddba2ce"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the stepsize. <br /></td></tr>
<tr class="separator:ac167993a5d156f544997b98ccddba2ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a71c5ac494cad5a976bb2c5a773494e34"><td class="memItemLeft" align="right" valign="top"><a id="a71c5ac494cad5a976bb2c5a773494e34"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTasOptimization_1_1GradientDescentState.html#a71c5ac494cad5a976bb2c5a773494e34">setX</a> (const double x_new[])</td></tr>
<tr class="memdesc:a71c5ac494cad5a976bb2c5a773494e34"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the current candidate point. <br /></td></tr>
<tr class="separator:a71c5ac494cad5a976bb2c5a773494e34"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9898e6f033fb79dd8ded28198bd19231"><td class="memItemLeft" align="right" valign="top"><a id="a9898e6f033fb79dd8ded28198bd19231"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTasOptimization_1_1GradientDescentState.html#a9898e6f033fb79dd8ded28198bd19231">setX</a> (const std::vector&lt; double &gt; &amp;x_new)</td></tr>
<tr class="memdesc:a9898e6f033fb79dd8ded28198bd19231"><td class="mdescLeft">&#160;</td><td class="mdescRight">Overload for when the input is a vector. <br /></td></tr>
<tr class="separator:a9898e6f033fb79dd8ded28198bd19231"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="friends"></a>
Friends</h2></td></tr>
<tr class="memitem:ae06820c4758e50752babeb3003c53fd1"><td class="memItemLeft" align="right" valign="top"><a class="el" href="structTasOptimization_1_1OptimizationStatus.html">OptimizationStatus</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTasOptimization_1_1GradientDescentState.html#ae06820c4758e50752babeb3003c53fd1">GradientDescent</a> (const <a class="el" href="group__OptimizationUtil.html#ga0242b256b00693a9af5f86d420e8f833">ObjectiveFunctionSingle</a> &amp;func, const <a class="el" href="group__OptimizationUtil.html#ga434ef512f644c87a3a796f106e792c4c">GradientFunctionSingle</a> &amp;grad, const <a class="el" href="group__OptimizationUtil.html#ga8545acbd43cc6058568433c442266679">ProjectionFunctionSingle</a> &amp;proj, const double increase_coeff, const double decrease_coeff, const int max_iterations, const double tolerance, <a class="el" href="classTasOptimization_1_1GradientDescentState.html">GradientDescentState</a> &amp;state)</td></tr>
<tr class="memdesc:ae06820c4758e50752babeb3003c53fd1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Applies the adaptive gradient descent algorithm on a restricted domain.  <a href="classTasOptimization_1_1GradientDescentState.html#ae06820c4758e50752babeb3003c53fd1">More...</a><br /></td></tr>
<tr class="separator:ae06820c4758e50752babeb3003c53fd1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afabe3cdc01e3cbf12d3b4e204c9aa3f5"><td class="memItemLeft" align="right" valign="top"><a class="el" href="structTasOptimization_1_1OptimizationStatus.html">OptimizationStatus</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTasOptimization_1_1GradientDescentState.html#afabe3cdc01e3cbf12d3b4e204c9aa3f5">GradientDescent</a> (const <a class="el" href="group__OptimizationUtil.html#ga0242b256b00693a9af5f86d420e8f833">ObjectiveFunctionSingle</a> &amp;func, const <a class="el" href="group__OptimizationUtil.html#ga434ef512f644c87a3a796f106e792c4c">GradientFunctionSingle</a> &amp;grad, const double increase_coeff, const double decrease_coeff, const int max_iterations, const double tolerance, <a class="el" href="classTasOptimization_1_1GradientDescentState.html">GradientDescentState</a> &amp;state)</td></tr>
<tr class="memdesc:afabe3cdc01e3cbf12d3b4e204c9aa3f5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Applies the adaptive gradient descent algorithm on unrestricted domain.  <a href="classTasOptimization_1_1GradientDescentState.html#afabe3cdc01e3cbf12d3b4e204c9aa3f5">More...</a><br /></td></tr>
<tr class="separator:afabe3cdc01e3cbf12d3b4e204c9aa3f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add4906f68843c248dceec6d40461d0aa"><td class="memItemLeft" align="right" valign="top"><a class="el" href="structTasOptimization_1_1OptimizationStatus.html">OptimizationStatus</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTasOptimization_1_1GradientDescentState.html#add4906f68843c248dceec6d40461d0aa">GradientDescent</a> (const <a class="el" href="group__OptimizationUtil.html#ga434ef512f644c87a3a796f106e792c4c">GradientFunctionSingle</a> &amp;grad, const double stepsize, const int max_iterations, const double tolerance, std::vector&lt; double &gt; &amp;state)</td></tr>
<tr class="memdesc:add4906f68843c248dceec6d40461d0aa"><td class="mdescLeft">&#160;</td><td class="mdescRight">Applies the constant step-size gradient descent algorithm for functions with unbounded domains.  <a href="classTasOptimization_1_1GradientDescentState.html#add4906f68843c248dceec6d40461d0aa">More...</a><br /></td></tr>
<tr class="separator:add4906f68843c248dceec6d40461d0aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Stores the information about a gradient descent run. </p>
<dl class="section user"><dt>class GradientDescentState</dt><dd>A state class associated with the Gradient Descent algorithm.</dd></dl>
<dl class="section user"><dt>Constructors and Copy/Move assignment</dt><dd>Constructors require information about an initial candidate point and initial step-size. The class is movable and copyable by constructor or operator=. Once set, the number of dimensions <b>cannot</b> be modified.<ul>
<li><a class="el" href="classTasOptimization_1_1GradientDescentState.html#a04076aba572ab88c4dff88ad126ad30c" title="The default constructor is NOT allowed.">GradientDescentState()</a></li>
<li><a class="el" href="classTasOptimization_1_1GradientDescentState.html#a86abeb7aeea4d77b18a9a89481246423" title="Return the number of dimensions.">getNumDimensions()</a></li>
</ul>
</dd></dl>
<dl class="section user"><dt>Set and Get Candidate and Stepsize</dt><dd>The Gradient Descent algorithm has one parameter, the step-size, and the current (best) point. The two have set/get methods with overloads for both std::vector and raw-arrays. Using common math conventions, the current best point is designated by <b>X</b>.<ul>
<li><a class="el" href="classTasOptimization_1_1GradientDescentState.html#a850e13087a8f62b401221a25c1214b12" title="Return the current candidate point.">getX()</a>, <a class="el" href="classTasOptimization_1_1GradientDescentState.html#a71c5ac494cad5a976bb2c5a773494e34" title="Set the current candidate point.">setX()</a></li>
<li><a class="el" href="classTasOptimization_1_1GradientDescentState.html#a83229d3db80c45620b7c093ee1beedf8" title="Return the stepsize.">getAdaptiveStepsize()</a>, <a class="el" href="classTasOptimization_1_1GradientDescentState.html#ac167993a5d156f544997b98ccddba2ce" title="Set the stepsize.">setAdaptiveStepsize()</a></li>
</ul>
</dd></dl>
<dl class="section user"><dt>Gradient Descent Algorithm</dt><dd>See <a class="el" href="group__OptimizationAlgorithm.html#ga8ed6c464920f331ace1d52231a68536e" title="Applies the constant step-size gradient descent algorithm for functions with unbounded domains.">TasOptimization::GradientDescent()</a></dd></dl>
<dl class="section user"><dt></dt><dd>More information about the gradient descent algorithm can be found in the following paper:</dd></dl>
<dl class="section user"><dt></dt><dd><blockquote class="doxtable">
<p>Nesterov, Y. (2013). Gradient methods for minimizing composite functions. <em>Mathematical programming</em>, 140(1), 125-161. </p>
</blockquote>
</dd></dl>
</div><h2 class="groupheader">Friends And Related Function Documentation</h2>
<a id="ae06820c4758e50752babeb3003c53fd1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae06820c4758e50752babeb3003c53fd1">&#9670;&nbsp;</a></span>GradientDescent <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="structTasOptimization_1_1OptimizationStatus.html">OptimizationStatus</a> GradientDescent </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="group__OptimizationUtil.html#ga0242b256b00693a9af5f86d420e8f833">ObjectiveFunctionSingle</a> &amp;&#160;</td>
          <td class="paramname"><em>func</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__OptimizationUtil.html#ga434ef512f644c87a3a796f106e792c4c">GradientFunctionSingle</a> &amp;&#160;</td>
          <td class="paramname"><em>grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__OptimizationUtil.html#ga8545acbd43cc6058568433c442266679">ProjectionFunctionSingle</a> &amp;&#160;</td>
          <td class="paramname"><em>proj</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const double&#160;</td>
          <td class="paramname"><em>increase_coeff</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const double&#160;</td>
          <td class="paramname"><em>decrease_coeff</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>max_iterations</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const double&#160;</td>
          <td class="paramname"><em>tolerance</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classTasOptimization_1_1GradientDescentState.html">GradientDescentState</a> &amp;&#160;</td>
          <td class="paramname"><em>state</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">friend</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Applies the adaptive gradient descent algorithm on a restricted domain. </p>
<p>Similar to the adaptive step-size algorithm on the unrestricted domain, but it uses a projection function to constrain each iterate to a user-defined domain.</p>
<p>The <b>proj</b> function computes the orthogonal projection of a point inside the domain, e.g., restricts the point to a hypercube. </p>

</div>
</div>
<a id="afabe3cdc01e3cbf12d3b4e204c9aa3f5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afabe3cdc01e3cbf12d3b4e204c9aa3f5">&#9670;&nbsp;</a></span>GradientDescent <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="structTasOptimization_1_1OptimizationStatus.html">OptimizationStatus</a> GradientDescent </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="group__OptimizationUtil.html#ga0242b256b00693a9af5f86d420e8f833">ObjectiveFunctionSingle</a> &amp;&#160;</td>
          <td class="paramname"><em>func</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__OptimizationUtil.html#ga434ef512f644c87a3a796f106e792c4c">GradientFunctionSingle</a> &amp;&#160;</td>
          <td class="paramname"><em>grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const double&#160;</td>
          <td class="paramname"><em>increase_coeff</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const double&#160;</td>
          <td class="paramname"><em>decrease_coeff</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>max_iterations</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const double&#160;</td>
          <td class="paramname"><em>tolerance</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classTasOptimization_1_1GradientDescentState.html">GradientDescentState</a> &amp;&#160;</td>
          <td class="paramname"><em>state</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">friend</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Applies the adaptive gradient descent algorithm on unrestricted domain. </p>
<p>Similar to the constant step-size algorithm <a class="el" href="classTasOptimization_1_1GradientDescentState.html#ae06820c4758e50752babeb3003c53fd1" title="Applies the adaptive gradient descent algorithm on a restricted domain.">GradientDescent()</a> but applying an adaptive stepping. This method is guaranteed to converge to a stationary point if the gradient of <b>f</b> is Lipschitz continuous on its domain. The algorithm is known as Non-Proximal, i.e., no restriction is applied to the domain which implies either work on an unbounded domain or the starting point and the minimum are sufficiently far from the boundary and the restriction is not needed.</p>
<p>This variant requires the value of the functional that is to be minimized, in addition to the gradient. There are two control parameters <b>increase_coeff</b> and <b>decrease_coeff</b> that guide the rate at which the step-size is adjusted. The parameters can affect the convergence rate, but not the final result.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">func</td><td>is the objective function to be minimized </td></tr>
    <tr><td class="paramname">grad</td><td>is the gradient of the objective function </td></tr>
    <tr><td class="paramname">increase_coeff</td><td>Controls how quickly the step-size is increased; should be greater than 1 </td></tr>
    <tr><td class="paramname">decrease_coeff</td><td>Controls how quickly the step-size is decreased; should be greater than 1 </td></tr>
    <tr><td class="paramname">max_iterations</td><td>Maximum number of iterations to perform </td></tr>
    <tr><td class="paramname">tolerance</td><td>same as in <a class="el" href="classTasOptimization_1_1GradientDescentState.html#ae06820c4758e50752babeb3003c53fd1" title="Applies the adaptive gradient descent algorithm on a restricted domain.">GradientDescent()</a> </td></tr>
    <tr><td class="paramname">state</td><td>Holds the state of the gradient descent algorithm, including the current iterate and the current adaptive step-size.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="structTasOptimization_1_1OptimizationStatus.html">TasOptimization::OptimizationStatus</a> struct that contains information about the last iterate. </dd></dl>

</div>
</div>
<a id="add4906f68843c248dceec6d40461d0aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#add4906f68843c248dceec6d40461d0aa">&#9670;&nbsp;</a></span>GradientDescent <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="structTasOptimization_1_1OptimizationStatus.html">OptimizationStatus</a> GradientDescent </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="group__OptimizationUtil.html#ga434ef512f644c87a3a796f106e792c4c">GradientFunctionSingle</a> &amp;&#160;</td>
          <td class="paramname"><em>grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const double&#160;</td>
          <td class="paramname"><em>stepsize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>max_iterations</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const double&#160;</td>
          <td class="paramname"><em>tolerance</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>state</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">friend</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Applies the constant step-size gradient descent algorithm for functions with unbounded domains. </p>
<p>Minimize a function with gradient <b>g</b> over an unconstrained domain. Perform work until reaching the desired tolerance (measured in the stationarity residual), or until <b>max_iterations</b> is reached. See also <a class="el" href="group__OptimizationUtil.html#gaa27bd012848274c59d0406c253d1e878">TasOptimization::computeStationarityResidual()</a></p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">grad</td><td>Gradient of the objective functional </td></tr>
    <tr><td class="paramname">stepsize</td><td>is the step-size of the algorithm </td></tr>
    <tr><td class="paramname">max_iterations</td><td>is the maximum number of iterations to perform </td></tr>
    <tr><td class="paramname">tolerance</td><td>Stationarity tolerance; the algorithm terminates when the stationarity residual computed by <a class="el" href="group__OptimizationUtil.html#gaa27bd012848274c59d0406c253d1e878">TasOptimization::computeStationarityResidual()</a> is less than or equal to <b>tolerance</b> </td></tr>
    <tr><td class="paramname">state</td><td>contains the current iterate and returns the best iterate. This algorithm does not use the adaptive step-size, so the state can be just a vector, but the signature accepts a <a class="el" href="classTasOptimization_1_1GradientDescentState.html" title="Stores the information about a gradient descent run.">GradientDescentState</a> with an automatic conversion.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="structTasOptimization_1_1OptimizationStatus.html">TasOptimization::OptimizationStatus</a> struct that contains information about the last iterate. </dd></dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>DREAM/Optimization/<a class="el" href="tsgGradientDescent_8hpp_source.html">tsgGradientDescent.hpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.8.15-->
<!-- start footer part -->
<!-- <div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
<!--  <ul>
    <li class="navelem"><a class="el" href="namespaceTasOptimization.html">TasOptimization</a></li><li class="navelem"><a class="el" href="classTasOptimization_1_1GradientDescentState.html">GradientDescentState</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div> -->
</body>
</html>
